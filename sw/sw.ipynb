{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 10:05:06.139678: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-31 10:05:06.518536: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-31 10:05:06.519658: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 10:05:07.590909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import larq as lq\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import templates"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 3,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def print_image(image):\n",
    "  # Squeeze the third dimension or you can use indexing to select the first slice\n",
    "  image_2d = np.squeeze(image)\n",
    "\n",
    "  # Plotting the image\n",
    "  plt.imshow(image_2d, cmap='gray')  # Use the gray colormap for grayscale\n",
    "  plt.colorbar()  # Optionally add a colorbar to see the intensity scale\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 6,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "print_image(train_images[0])\n",
    "# Normalize pixel values to be between -1 and 1\n",
    "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputShapeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.input_shapes = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                input_shape = layer.input_shape\n",
    "                self.input_shapes.append((layer.name, input_shape))\n",
    "                print(f\"Layer: {layer.name}, Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
=======
   "execution_count": 20,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
<<<<<<< HEAD
      "938/938 [==============================] - 17s 17ms/step - loss: 0.6551 - accuracy: 0.9079\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.5013 - accuracy: 0.9574\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.4765 - accuracy: 0.9644\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.4685 - accuracy: 0.9661\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.4591 - accuracy: 0.9708\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.4570 - accuracy: 0.9705\n"
=======
      "938/938 [==============================] - 1s 610us/step - loss: 3.9883 - accuracy: 0.7582\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 1s 570us/step - loss: 3.0133 - accuracy: 0.8225\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 1s 581us/step - loss: 2.9748 - accuracy: 0.8265\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 1s 591us/step - loss: 3.0102 - accuracy: 0.8291\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 1s 571us/step - loss: 3.0290 - accuracy: 0.8293\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 1s 569us/step - loss: 2.9888 - accuracy: 0.8307\n"
>>>>>>> main
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<keras.src.callbacks.History at 0x1eea36fce80>"
      ]
     },
     "execution_count": 5,
=======
       "<keras.callbacks.History at 0x7fcf600b8550>"
      ]
     },
     "execution_count": 20,
>>>>>>> main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN Topology\n",
    "\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "input_shape = (28, 28, 1) # Input img shape\n",
    "filters_a = 32 # Number of output channels\n",
    "kernel_three = (4, 4) # Kernel dimension\n",
<<<<<<< HEAD
    "\n",
    "filters_b = 32 # Number of output channels\n",
    "kernel_b = (3, 3) # Kernel dimension\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(filters_a, kernel_three,\n",
    "                                input_quantizer=\"ste_sign\",\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(lq.layers.QuantConv2D(filters_b, kernel_b,\n",
    "                                input_quantizer=\"ste_sign\",\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
=======
    "\n",
    "filters_b = 32 # Number of output channels\n",
    "kernel_b = (3, 3) # Kernel dimension\n",
    "\n",
    "# model.add(lq.layers.QuantConv2D(filters_a, kernel_three,\n",
    "#                                 input_quantizer=\"ste_sign\",\n",
    "#                                 kernel_quantizer=\"ste_sign\",\n",
    "#                                 kernel_constraint=\"weight_clip\",\n",
    "#                                 use_bias=False,\n",
    "#                                 input_shape=input_shape))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "# model.add(lq.layers.QuantConv2D(filters_b, kernel_b,\n",
    "#                                 input_quantizer=\"ste_sign\",\n",
    "#                                 kernel_quantizer=\"ste_sign\",\n",
    "#                                 kernel_constraint=\"weight_clip\",\n",
    "#                                 use_bias=False,\n",
    "#                                 input_shape=input_shape))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "# model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "# model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "# model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "# model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# model.add(lq.layers.QuantDense(500, use_bias=False, **kwargs))\n",
>>>>>>> main
    "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))\n",
<<<<<<< HEAD
    "# model.add(tf.keras.layers.Flatten())\n",
    "# # model.add(lq.layers.QuantDense(500, use_bias=False, **kwargs))\n",
    "# model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "# model.add(tf.keras.layers.Activation(\"softmax\"))\n",
=======
>>>>>>> main
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, batch_size=64, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 21,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5120 - accuracy: 0.9691\n",
      "+sequential stats-----------------------------------------------------------------------------+\n",
      "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs |\n",
      "|                              (bit)                        x 1       x 1    (kB)             |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d                     1  (-1, 25, 25, 32)      512         0    0.06      320000 |\n",
      "| max_pooling2d                    -  (-1, 12, 12, 32)        0         0       0           0 |\n",
      "| batch_normalization              -  (-1, 12, 12, 32)        0        64    0.25           0 |\n",
      "| quant_conv2d_1                   1  (-1, 10, 10, 32)     9216         0    1.12      921600 |\n",
      "| max_pooling2d_1                  -    (-1, 5, 5, 32)        0         0       0           0 |\n",
      "| batch_normalization_1            -    (-1, 5, 5, 32)        0        64    0.25           0 |\n",
      "| flatten                          -         (-1, 800)        0         0       0           0 |\n",
      "| quant_dense                      1         (-1, 128)   102400         0   12.50      102400 |\n",
      "| batch_normalization_2            -         (-1, 128)        0       256    1.00           0 |\n",
      "| quant_dense_1                    1          (-1, 10)     1280         0    0.16        1280 |\n",
      "| batch_normalization_3            -          (-1, 10)        0        20    0.08           0 |\n",
      "| activation                       -          (-1, 10)        0         0       0           ? |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "| Total                                                  113408       404   15.42     1345280 |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "+sequential summary----------------------------+\n",
      "| Total params                      114 k      |\n",
      "| Trainable params                  113 k      |\n",
      "| Non-trainable params              404        |\n",
      "| Model size                        15.42 KiB  |\n",
      "| Model size (8-bit FP weights)     14.24 KiB  |\n",
      "| Float-32 Equivalent               444.58 KiB |\n",
      "| Compression Ratio of Memory       0.03       |\n",
      "| Number of MACs                    1.35 M     |\n",
      "| Ratio of MACs that are binarized  1.0000     |\n",
      "+----------------------------------------------+\n"
=======
      "313/313 [==============================] - 0s 392us/step - loss: 3.1394 - accuracy: 0.8075\n",
      "+sequential_11 stats--------------------------------------------------+\n",
      "| Layer           Input prec.    Outputs  # 1-bit  Memory  1-bit MACs |\n",
      "|                       (bit)                 x 1    (kB)             |\n",
      "+---------------------------------------------------------------------+\n",
      "| flatten_4                 -  (-1, 784)        0       0           0 |\n",
      "| quant_dense_20            1   (-1, 10)     7840    0.96        7840 |\n",
      "| activation_9              -   (-1, 10)        0       0           ? |\n",
      "+---------------------------------------------------------------------+\n",
      "| Total                                      7840    0.96        7840 |\n",
      "+---------------------------------------------------------------------+\n",
      "+sequential_11 summary------------------------+\n",
      "| Total params                      7.84 k    |\n",
      "| Trainable params                  7.84 k    |\n",
      "| Non-trainable params              0         |\n",
      "| Model size                        980.00 B  |\n",
      "| Model size (8-bit FP weights)     980.00 B  |\n",
      "| Float-32 Equivalent               30.62 KiB |\n",
      "| Compression Ratio of Memory       0.03      |\n",
      "| Number of MACs                    7.84 k    |\n",
      "| Ratio of MACs that are binarized  1.0000    |\n",
      "+---------------------------------------------+\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
    "# Train NN\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "lq.models.summary(model)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 71,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Layer: batch_normalization\n",
      "  Beta (offset): [-0.2628228   0.15782718 -0.5284099  -0.74273616 -0.45367378 -0.10186193\n",
      "  0.08579124 -0.6890928  -0.32662195  0.09673755 -0.5273635  -0.30948326\n",
      "  0.0630685  -0.08210813 -0.10889392 -0.8415992  -0.01688982  0.08890344\n",
      " -0.9302154  -0.5355635  -0.2334577  -0.2172808   0.33246627 -0.4725801\n",
      " -0.42205152 -0.5039059  -0.4523534  -0.35837477 -0.19038872 -0.29852945\n",
      " -0.17643832 -0.17784601]\n",
      "Beta Length: 32\n",
      "  Moving Mean: [ 3.4323437e+00 -2.1056681e+00  5.5281539e+00  2.1725578e+00\n",
      "  4.9445000e+00 -2.2714612e+00 -4.3038783e+00  1.6431963e+00\n",
      "  6.5336823e+00  9.8812485e-01  5.5441184e+00  4.4932141e+00\n",
      "  1.3896981e+00  1.4919758e+00  4.9273195e+00  2.0640695e-03\n",
      "  4.0103827e+00 -9.1125751e-01  3.0586777e+00  3.6862829e+00\n",
      "  2.3022871e+00 -3.2105241e+00  1.7149311e-01  4.7599645e+00\n",
      "  3.0859766e+00  7.0029445e+00  6.4772539e+00  3.4938393e+00\n",
      " -8.4544577e-02  4.9399252e+00 -2.8701439e+00  3.1680629e+00]\n",
      " Moving Mean Length: 32\n",
      "  Moving Variance: [13.786972  22.20536   13.299894  13.846208  14.424442  22.667622\n",
      " 35.504078  15.41053   14.926575   9.389952  10.537726  15.406578\n",
      " 11.823678   9.417928  14.74118   18.814175  10.814454  17.279972\n",
      " 13.697441   6.9819193  7.783469  35.27754   12.861839  13.014598\n",
      "  9.938338  16.86003   13.833534   5.9282637 14.924639   8.990811\n",
      " 18.33156    9.733183 ]\n",
      "  Moving Variance Length: 32\n",
      "Layer: batch_normalization_1\n",
      "  Beta (offset): [-0.68165576 -0.14947309  0.21325336 -0.31937727 -0.28908277 -0.5997595\n",
      " -0.25210035 -0.08052632 -0.37940896 -0.40768585 -0.27423334 -0.3610559\n",
      " -0.4578249  -0.31957737 -0.36469182 -0.15661666 -0.07305408  0.08892909\n",
      " -0.43004113 -0.19803384 -0.04664251 -0.19871601 -0.05899918 -0.25734925\n",
      " -0.4827718  -0.44585818 -0.253395   -0.09441228 -0.24494185 -0.16847776\n",
      " -0.22777377  0.07177211]\n",
      "Beta Length: 32\n",
      "  Moving Mean: [ 10.785518    18.852667    14.399407    22.867664    29.429893\n",
      "  15.21393     25.914051    14.001549    28.164623    23.57393\n",
      "  12.565091     4.716939    20.926779    -5.9655404   29.178104\n",
      "  36.9672      25.163193    18.866505    12.581349    35.112747\n",
      " -19.432905    12.940775    13.973521    -1.4255333   11.920283\n",
      "  11.884266    -0.25636345  20.169077    37.19634     17.942554\n",
      "  16.313082    24.452436  ]\n",
      " Moving Mean Length: 32\n",
      "  Moving Variance: [ 608.44464  593.9388  1006.51416 1176.298   1204.0198   696.9962\n",
      "  802.8553   822.61255  710.98505  916.98987  669.3415   542.7021\n",
      "  460.1299   891.0971   445.4519   577.60266  783.0407  1011.3298\n",
      "  514.8986   774.40643  736.4033   932.77527  729.92114  551.9129\n",
      " 1210.9823   581.8936   894.75793  719.248    890.9019   967.17255\n",
      "  600.4479   671.73724]\n",
      "  Moving Variance Length: 32\n",
      "Layer: batch_normalization_2\n",
      "  Beta (offset): [ 3.1087756e-01  8.3273751e-01 -6.5531904e-01  6.2687880e-01\n",
      " -7.6575679e-01 -8.3633572e-01  3.9056575e-01  6.3347042e-01\n",
      "  7.2349912e-01 -5.3639400e-01  8.1579435e-01  1.1759432e-01\n",
      "  3.4856376e-01  4.1972536e-01 -4.4649577e-01  4.4872996e-01\n",
      " -8.7243997e-02  3.3170360e-01 -9.7543940e-02 -2.0114002e-01\n",
      "  8.2264996e-01 -4.0711957e-01 -4.3866104e-01  3.9758283e-01\n",
      " -7.2350311e-01 -1.1772913e-01  4.6040297e-01 -4.8523656e-01\n",
      " -3.6077967e-01 -2.0182601e-01 -2.3279782e-01 -6.7063522e-01\n",
      " -1.3204354e-01  7.0088065e-01  9.0618539e-01 -5.3060198e-01\n",
      "  3.5036293e-01  3.4029078e-01 -7.4002618e-01  3.9049679e-01\n",
      "  3.5433593e-01 -8.2541311e-01 -3.6348683e-01 -4.5608470e-01\n",
      " -2.5942460e-01 -3.4150958e-01 -6.0816538e-01 -3.0962631e-01\n",
      " -9.0459667e-02 -6.2288757e-02  6.3512725e-01 -5.0258505e-01\n",
      "  6.5397131e-01 -5.3188664e-01  2.6987877e-01  1.6091363e-01\n",
      "  6.1410713e-01 -5.9143323e-01 -7.6087826e-01 -1.5238632e-01\n",
      "  5.8874056e-02 -1.6812959e-01  3.6633870e-01 -3.4410554e-01\n",
      "  3.5051936e-01  4.1655809e-01 -8.0328012e-01  3.9892739e-01\n",
      "  1.6625081e-01 -6.5619725e-01 -2.5308263e-01  4.8935530e-01\n",
      "  5.7947809e-01 -2.3261569e-01  3.3001655e-01 -5.9698099e-01\n",
      "  3.5587615e-01  3.5267991e-01 -6.8411750e-01 -6.3049763e-01\n",
      "  4.2543289e-01  6.6394973e-01 -7.2479213e-04 -6.1572301e-01\n",
      "  6.4379036e-01 -4.1279033e-01 -3.0116466e-01  9.0675539e-01\n",
      "  1.3049643e-01 -2.0249724e-01 -1.3522302e-01 -5.2872211e-02\n",
      "  6.1510183e-02  2.2423401e-02  5.3381540e-02 -7.1629745e-01\n",
      " -7.2563499e-01  9.7656902e-04  3.4218484e-01 -1.6756363e-01\n",
      " -4.5104599e-01 -1.3389004e-02  3.3867249e-01  4.7029597e-01\n",
      "  7.7955109e-01 -7.1497715e-01  3.2805938e-01 -5.8593416e-01\n",
      " -4.1073644e-01  5.8592522e-01 -4.1073996e-01 -7.6329672e-01\n",
      "  3.8696006e-01  7.4208361e-01  5.7336050e-01 -1.0482599e-01\n",
      "  4.4603753e-01  2.4170324e-01 -4.0781492e-01 -1.5299605e-01\n",
      "  3.9651658e-02 -1.5642118e-01  6.3276619e-01  4.7317228e-01\n",
      " -2.5835503e-02 -2.9069671e-01 -8.8073552e-01 -5.8437485e-01]\n",
      "Beta Length: 128\n",
      "  Moving Mean: [ -9.618614     9.736047     8.656762    25.686842     2.2020984\n",
      "  30.073727    -5.9175305   36.750282   -47.24385    -10.111232\n",
      "  12.067039    -3.945953   -14.828807    11.282125    -9.0278845\n",
      "  -8.239286   -40.678097   -21.181576    -4.813976    -6.5870867\n",
      " -39.78482    -22.850908    -6.805316    32.26501    -12.364519\n",
      "  34.84349    -17.417192   -17.240969    -6.9258246   45.28194\n",
      "  -8.431525    24.571812   -47.09066      3.4012437  -13.089023\n",
      "  24.326199    -5.888784    26.616116     0.25452906  26.272892\n",
      " -15.142632    19.46348     52.42518    -28.835283     9.30226\n",
      " -16.577457    19.541594    -9.521588     1.1130837   56.24633\n",
      "   6.541504    19.024359   -11.2179365  -18.456055    -0.3250348\n",
      " -25.332836    12.526938    -9.840475   -14.050634    64.249985\n",
      " -21.67313     58.39968    -30.902514    25.675095   -20.808474\n",
      "  49.356297   -27.838066     8.675875    12.426544    -6.8450007\n",
      " -19.88065     -8.063787    21.03678     23.85866     10.651992\n",
      " -16.825832    -8.021362     2.3698626  -15.248103    50.288704\n",
      " -16.420103    -5.8387103  -46.17801     10.442007   -31.30389\n",
      " -19.744469   -18.003187   -28.141369    24.80047     -7.4715285\n",
      "  29.831146    27.808401    -8.492979   -32.71984     -5.4737077\n",
      "  23.716036    -3.97893     25.505606    24.72886     40.32223\n",
      "  11.216953     0.71204615  35.800938    -5.7027764  -34.119987\n",
      "  16.153069    -9.435159    -8.291323    -2.1019146   -9.546007\n",
      "  11.4684     -20.256134    45.80001     48.155457     8.340434\n",
      "  28.41561     22.427214   -29.543531    -2.1288242   -7.5198407\n",
      "  -7.333394     7.2796125  -17.233473    26.812574   -28.850315\n",
      "  19.792519    16.945536   -13.890406  ]\n",
      " Moving Mean Length: 128\n",
      "  Moving Variance: [3820.6736 4358.2544 2783.7192 4534.32   3014.1287 3902.8845 3091.897\n",
      " 3689.7075 2851.3665 3298.2473 2488.2239 2364.402  2617.24   2728.9868\n",
      " 2227.0835 3406.3025 4066.937  2260.6113 2367.7686 2397.7625 2720.785\n",
      " 2352.6848 2212.3193 3695.7751 2875.8652 2794.4111 2769.5173 2971.5488\n",
      " 3285.4036 2408.6897 3157.728  3719.4888 3343.3384 4307.8413 3773.1143\n",
      " 4316.031  3024.544  3299.809  3798.5117 2407.8894 3072.085  3218.4631\n",
      " 2318.225  2730.273  3055.6526 3263.1619 2435.632  3217.138  2785.5457\n",
      " 3490.5007 3338.7722 3412.8728 3725.8906 3010.0063 2728.9333 2644.582\n",
      " 2829.076  3713.7676 4446.3203 2761.2751 2974.0608 2423.438  3042.429\n",
      " 3783.2568 3164.173  4097.7397 3119.8926 3542.9768 2853.558  4396.3433\n",
      " 2266.3489 3353.0737 3885.1675 2251.2437 3069.4802 2367.2195 3753.0337\n",
      " 2280.832  2894.2866 3676.991  3671.199  3418.9292 2525.1697 3050.0605\n",
      " 3343.7554 4216.7305 2884.166  5217.398  3016.3657 3285.7146 3579.4492\n",
      " 6275.5107 2417.7605 2593.512  2740.971  2877.167  5105.863  2463.7505\n",
      " 3087.0063 2291.2214 3303.932  2914.8918 2644.2083 3914.077  2770.2236\n",
      " 3568.323  3722.3508 3625.915  4876.988  2618.386  4673.6465 2539.8909\n",
      " 3497.0417 3980.2383 2599.1716 3482.225  2849.4565 3718.0005 2766.7812\n",
      " 2800.7607 3244.4946 3157.6843 3002.7034 2965.5244 2341.2532 3989.0564\n",
      " 3500.2493 3403.165 ]\n",
      "  Moving Variance Length: 128\n",
      "Layer: batch_normalization_3\n",
      "  Beta (offset): [-0.03744338  0.1365801  -0.00618035  0.02489143 -0.03111445 -0.12472054\n",
      " -0.02390216  0.05722433 -0.02509599  0.00225018]\n",
      "Beta Length: 10\n",
      "  Moving Mean: [ 0.9470701   0.84210294  5.1105103   1.827017    0.92747265  1.8755777\n",
      " -2.7493522   0.69422877 12.361806    2.061283  ]\n",
      " Moving Mean Length: 10\n",
      "  Moving Variance: [746.3206  888.87976 673.55774 676.09    680.43066 662.28986 774.8725\n",
      " 644.99896 617.69403 593.5267 ]\n",
      "  Moving Variance Length: 10\n"
=======
      "[array([[-1.,  1.,  1., ..., -1., -1.,  1.],\n",
      "       [ 1.,  1., -1., ..., -1., -1., -1.],\n",
      "       [ 1., -1., -1., ..., -1.,  1.,  1.],\n",
      "       ...,\n",
      "       [-1.,  1.,  1., ...,  1., -1., -1.],\n",
      "       [-1.,  1., -1., ..., -1., -1., -1.],\n",
      "       [ 1.,  1.,  1., ..., -1.,  1.,  1.]], dtype=float32)] 784 10\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# # Extract weights\n",
    "# with lq.context.quantized_scope(True):\n",
    "#     weights = model.layers[3].get_weights()\n",
    "#     print(weights)\n",
    "\n",
    "#     if len(weights) > 0:\n",
    "#         weight_array = weights[0] \n",
    "#         print(\"Weights shape:\", weight_array.shape)\n",
    "#     else:\n",
    "#         print(\"No weights found in this layer.\")\n",
=======
    "# Extract weights\n",
    "with lq.context.quantized_scope(True):\n",
    "    weights = model.layers[1].get_weights()\n",
    "    print(weights, len(weights[0]), len(weights[0][0]))\n",
    "\n",
>>>>>>> main
    "\n",
    "# print(weights[0].shape)\n",
    "# rows, cols, _, output_channels = weights[0].shape\n",
    "# print(rows, cols, output_channels)\n",
    "# for col in range(cols):\n",
    "#     for row in range(rows):\n",
    "#         for output_channel in range(output_channels):\n",
<<<<<<< HEAD
    "#             print(row, col, output_channel, weights[0][row][col][0][output_channel])\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        beta, moving_mean, moving_variance = layer.get_weights()\n",
    "        print(f\"Layer: {layer.name}\")\n",
    "        print(f\"  Beta (offset): {beta}\")\n",
    "        print(f\"Beta Length: {len(beta)}\")\n",
    "        print(f\"  Moving Mean: {moving_mean}\")\n",
    "        print(f\" Moving Mean Length: {len(moving_mean)}\")\n",
    "        print(f\"  Moving Variance: {moving_variance}\")\n",
    "        print(f\"  Moving Variance Length: {len(moving_variance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: batch_normalization, Input shape: (None, 12, 12, 32)\n",
      "Layer: batch_normalization_1, Input shape: (None, 5, 5, 32)\n",
      "Layer: batch_normalization_2, Input shape: (None, 128)\n",
      "Layer: batch_normalization_3, Input shape: (None, 10)\n"
     ]
    }
   ],
   "source": [
    "input_shape_callback = InputShapeCallback()\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        input_shape = layer.input_shape\n",
    "        print(f\"Layer: {layer.name}, Input shape: {input_shape}\")"
=======
    "#             print(row, col, output_channel, weights[0][row][col][0][output_channel])"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 7\n"
     ]
    }
   ],
   "source": [
    "print_image(test_images[0]) # test_images[0]\n",
    "flatten_image = []\n",
    "for row in test_images[0]:\n",
    "    for column in row:\n",
    "        flatten_image.append(column)\n",
    "flatten_image = np.array(flatten_image).T\n",
    "fc_classification = np.matmul(flatten_image,weights[0])\n",
    "prediction = np.argmax(fc_classification)\n",
    "print(\"Predicted:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "def parse_fc(fc_weights):\n",
    "    fc_weights[fc_weights == -1] = 0\n",
    "    return fc_weights.T\n",
    "    # for input_neuron in binarized_weights:\n",
    "    #     # print(len(input_neuron))\n",
    "\n",
    "print(parse_fc(weights[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gen_hdl/fc_layer.v'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m FC_TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mmodule layer_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mLAYER_NUM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_fc #(\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m    parameter INPUT_DIM = 784,\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    parameter OUTPUT_DIM = 10,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124mendmodule\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgen_hdl/fc_layer.v\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     31\u001b[0m   f\u001b[38;5;241m.\u001b[39mwrite(FC_TEMPLATE)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gen_hdl/fc_layer.v'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if isinstance(layer, lq.layers.QuantConv2D):\n",
    "        weights = layer.get_weights()\n",
    "        print(f\"Layer: {layer.name}\")\n",
    "        print(f\"  Weights: {weights}\")\n",
    "        print(f\"  Weights Length: {len(weights)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"gen_hdl\"):\n",
    "    os.mkdir(\"gen_hdl\")\n",
    "\n",
    "# Extract weights\n",
    "betas = []\n",
    "moving_means = []\n",
    "moving_variances = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        beta, moving_mean, moving_variance = layer.get_weights()\n",
    "        betas.append(beta)\n",
    "        moving_means.append(moving_mean)\n",
    "        moving_variances.append(moving_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bn(beta, moving_mean, moving_variance, num: int):\n",
    "\n",
    "    # thresholds = np.zeros(len(beta))\n",
    "    compare = \"\"\n",
    "    for output_neuron in range(len(beta)):\n",
    "        # print(len(beta))\n",
    "        threshold = moving_mean[output_neuron] - beta[output_neuron] * np.sqrt(moving_variance[output_neuron])\n",
    "        compare += f\"   assign o_data[{output_neuron}] = i_data[{output_neuron}] > {threshold} ? 1 : 0;\\n\"\n",
    "\n",
    "    output_hdl = templates.BN_TEMPLATE \\\n",
    "        .replace(\"%DIM_DATA%\", str(len(beta))) \\\n",
    "        .replace(\"%LAYER_NUM%\", str(num)) \\\n",
    "        .replace(\"%COMPARE%\", compare)\n",
    "        \n",
    "    with open(f\"gen_hdl/bn_layer_{num}.v\", \"w\") as f:\n",
    "        f.write(output_hdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(betas)):\n",
    "    parse_bn(betas[n], moving_means[n], moving_variances[n], n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.7957 - accuracy: 0.8504\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.6196 - accuracy: 0.9059\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.5825 - accuracy: 0.9164\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.5620 - accuracy: 0.9234\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.9290\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eea36012b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\")\n",
    "\n",
    "\n",
    "model_new = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "\n",
    "model_new.add(tf.keras.layers.Flatten(input_shape=input_shape))\n",
    "\n",
    "# # 128 neurons\n",
    "# model_new.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "# model_new.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# 64 neurons\n",
    "model_new.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "model_new.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# 32 neurons\n",
    "model_new.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "model_new.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# 10 neurons\n",
    "model_new.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "model_new.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_new.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model_new.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_new.fit(train_images, train_labels, batch_size=64, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.9376\n",
      "+sequential_4 stats---------------------------------------------------------------------+\n",
      "| Layer                   Input prec.    Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs |\n",
      "|                               (bit)                 x 1       x 1    (kB)             |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| flatten_4                         -  (-1, 784)        0         0       0           0 |\n",
      "| quant_dense_12                    1  (-1, 128)   100352         0   12.25      100352 |\n",
      "| batch_normalization_14            -  (-1, 128)        0       256    1.00           0 |\n",
      "| quant_dense_13                    1  (-1, 128)    16384         0    2.00       16384 |\n",
      "| batch_normalization_15            -  (-1, 128)        0       256    1.00           0 |\n",
      "| quant_dense_14                    1   (-1, 10)     1280         0    0.16        1280 |\n",
      "| batch_normalization_16            -   (-1, 10)        0        20    0.08           0 |\n",
      "| activation_4                      -   (-1, 10)        0         0       0           ? |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Total                                            118016       532   16.48      118016 |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "+sequential_4 summary--------------------------+\n",
      "| Total params                      119 k      |\n",
      "| Trainable params                  118 k      |\n",
      "| Non-trainable params              532        |\n",
      "| Model size                        16.48 KiB  |\n",
      "| Model size (8-bit FP weights)     14.93 KiB  |\n",
      "| Float-32 Equivalent               463.08 KiB |\n",
      "| Compression Ratio of Memory       0.04       |\n",
      "| Number of MACs                    118 k      |\n",
      "| Ratio of MACs that are binarized  1.0000     |\n",
      "+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_new.evaluate(test_images, test_labels)\n",
    "lq.models.summary(model_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
