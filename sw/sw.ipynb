{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import larq as lq\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.keras import initializers, regularizers, constraints\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import standard_ops\n",
    "\n",
    "import templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def print_image(image):\n",
    "  # Squeeze the third dimension or you can use indexing to select the first slice\n",
    "  image_2d = np.squeeze(image)\n",
    "\n",
    "  # Plotting the image\n",
    "  plt.imshow(image_2d, cmap='gray')  # Use the gray colormap for grayscale\n",
    "  plt.colorbar()  # Optionally add a colorbar to see the intensity scale\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "print_image(train_images[0])\n",
    "# Normalize pixel values to be between -1 and 1\n",
    "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputShapeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.input_shapes = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                input_shape = layer.input_shape\n",
    "                self.input_shapes.append((layer.name, input_shape))\n",
    "                print(f\"Layer: {layer.name}, Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heights: [25, 25, 23, 23, None, None, None, None, None, None]\n",
      "Widths: [25, 25, 23, 23, None, None, None, None, None, None]\n",
      "Channels: [32, 32, 32, 32, 16928, 128, 128, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# NN Topology\n",
    "\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "input_shape = (28, 28, 1) # Input img shape\n",
    "filters_a = 32 # Number of output channels\n",
    "kernel_three = (4, 4) # Kernel dimension\n",
    "\n",
    "filters_b = 32 # Number of output channels\n",
    "kernel_b = (3, 3) # Kernel dimension\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(filters_a, kernel_three,\n",
    "                                input_quantizer=\"ste_sign\",\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=input_shape))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(filters_b, kernel_b,\n",
    "                                input_quantizer=\"ste_sign\",\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=input_shape))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# # model.add(lq.layers.QuantDense(500, use_bias=False, **kwargs))\n",
    "# model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "# model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "output_shapes = [layer.output_shape for layer in model.layers]\n",
    "\n",
    "heights = []\n",
    "widths = []\n",
    "channels = []\n",
    "\n",
    "for shape in output_shapes:\n",
    "    if len(shape) == 4:  \n",
    "        _, height, width, channel = shape\n",
    "        heights.append(height)\n",
    "        widths.append(width)\n",
    "        channels.append(channel)\n",
    "    elif len(shape) == 2:  \n",
    "        _, channel = shape\n",
    "        heights.append(None)\n",
    "        widths.append(None)\n",
    "        channels.append(channel)\n",
    "\n",
    "print(\"Heights:\", heights)\n",
    "print(\"Widths:\", widths)\n",
    "print(\"Channels:\", channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "938/938 [==============================] - 65s 69ms/step - loss: 0.5600 - accuracy: 0.9360\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.4828 - accuracy: 0.9629\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 64s 69ms/step - loss: 0.4748 - accuracy: 0.9656\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 66s 70ms/step - loss: 0.4677 - accuracy: 0.9687\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 59s 63ms/step - loss: 0.4602 - accuracy: 0.9708\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 57s 61ms/step - loss: 0.4529 - accuracy: 0.9734\n",
      "Conv layer 1 weights shape: [(4, 4, 1, 32)]\n",
      "Conv layer 2 weights shape: [(3, 3, 32, 32)]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, batch_size=64, epochs=6)\n",
    "\n",
    "conv_weights = []\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, lq.layers.QuantConv2D):\n",
    "        weights = layer.get_weights()  \n",
    "        conv_weights.append(weights)\n",
    "\n",
    "\n",
    "for idx, weights in enumerate(conv_weights):\n",
    "    print(f\"Conv layer {idx + 1} weights shape: {[w.shape for w in weights]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-3.65354829e-02  3.42605621e-01  1.11490060e-02  1.90659806e-01\n",
      "    -5.57024684e-03  4.42363031e-04  5.77575743e-01  3.57662663e-02\n",
      "     1.66008249e-03  2.06673387e-02 -4.00859630e-03  3.72561932e-01\n",
      "     1.26805380e-01  2.29202434e-01 -3.90716970e-01 -7.82470524e-01\n",
      "     6.57926083e-01 -2.27767259e-01  2.35837942e-05 -1.31718710e-01\n",
      "    -5.82134008e-01  4.44326596e-03  8.30373168e-01 -3.97226587e-02\n",
      "    -9.59319174e-02 -7.99257606e-02  2.15194672e-01 -9.98528849e-05\n",
      "    -5.35036623e-01 -1.44872159e-01  1.79196030e-01 -5.67205667e-01]]\n",
      "\n",
      "  [[ 2.01290916e-03  3.35821033e-01 -3.45111996e-01  1.52577519e-01\n",
      "     9.10715833e-02 -3.10630262e-01  7.79323339e-01 -1.11269005e-01\n",
      "     7.17715383e-01  6.89680129e-02 -4.67170812e-02  3.56150836e-01\n",
      "    -3.03895853e-04 -1.61509216e-02 -3.23024299e-03 -9.99746561e-01\n",
      "     2.47470453e-01 -2.08936427e-02 -7.18478113e-03 -1.68663971e-02\n",
      "    -2.53840476e-01 -1.47170484e-01  4.19462293e-01  2.03019828e-02\n",
      "    -1.46289659e-03 -9.56496000e-02 -2.03704149e-01  1.00857250e-01\n",
      "    -6.09396398e-01 -1.60368100e-01  3.02657694e-01 -5.50748527e-01]]\n",
      "\n",
      "  [[ 2.57500499e-01  2.98026105e-04 -1.00000000e+00  1.70970231e-01\n",
      "     1.45283952e-01 -7.72854447e-01  3.78378421e-01 -6.04764581e-01\n",
      "     1.00000000e+00  9.04774517e-02  2.43416551e-04  1.59280330e-01\n",
      "    -1.89291015e-01 -2.73851424e-01  1.50595859e-01 -7.17372894e-01\n",
      "     5.38849160e-02  3.23799521e-01 -1.93355203e-01 -9.01508406e-02\n",
      "    -5.14607430e-01 -3.22640210e-01  5.09652356e-03  2.92977333e-01\n",
      "    -3.15846562e-01 -5.51934391e-02 -3.63305748e-01  3.01033586e-01\n",
      "    -5.28366804e-01 -2.27432027e-01  3.72669220e-01 -8.56034865e-04]]\n",
      "\n",
      "  [[ 1.00000000e+00 -3.94647837e-01 -4.13788468e-01  1.83468536e-01\n",
      "    -4.55470197e-03 -8.36520940e-02 -3.46941059e-04 -2.68238395e-01\n",
      "     4.27672178e-01  2.04074711e-01 -1.27291217e-01 -7.77583644e-02\n",
      "    -3.84199947e-01 -5.36502302e-02  3.17959160e-01 -6.65591002e-01\n",
      "     7.45482802e-01  5.26708901e-01 -3.43458682e-01 -6.07357770e-02\n",
      "    -6.19116068e-01 -4.88562614e-01  1.63930252e-01  5.26246428e-01\n",
      "    -3.94082457e-01 -1.38231114e-01  1.12215122e-02 -1.04009047e-01\n",
      "    -3.17499757e-01 -6.71306551e-02  2.21113265e-01  3.13850403e-01]]]\n",
      "\n",
      "\n",
      " [[[ 6.02261536e-03  1.24163561e-01  2.25632593e-01 -3.67628061e-03\n",
      "    -1.00000000e+00  4.37182821e-02  3.43688339e-01  1.23463482e-01\n",
      "     5.01017645e-03  1.02654449e-04  4.88043934e-01  9.54720527e-02\n",
      "     5.51698744e-01  3.19688231e-01 -7.25070119e-01 -5.98496437e-01\n",
      "     1.00000000e+00 -2.83598481e-03  2.05282614e-01  1.54319284e-02\n",
      "    -1.44968599e-01  4.77748007e-01  4.42369699e-01 -1.50946572e-01\n",
      "     8.78795683e-02 -2.96416623e-03  6.17847621e-01 -1.85879245e-01\n",
      "    -5.39816082e-01 -1.05765216e-01  2.33329713e-01 -8.32362294e-01]]\n",
      "\n",
      "  [[ 4.86313961e-02 -8.33357451e-04 -3.44401062e-01 -2.20041629e-03\n",
      "    -1.00000000e+00 -6.61375284e-01  4.51812416e-01 -4.07996885e-02\n",
      "     9.99337912e-01 -1.17729488e-03  1.29324079e-01  3.99415800e-03\n",
      "     4.16034728e-01 -1.62519002e-03 -8.42320085e-01 -6.18569314e-01\n",
      "     9.96191680e-01 -3.40716809e-01  1.62339032e-01 -1.44783640e-04\n",
      "    -2.58199602e-01  1.94353983e-01  3.91603500e-01  4.48765568e-02\n",
      "     5.36883846e-02  3.55088688e-03  3.18195015e-01  7.18185604e-01\n",
      "    -8.86787698e-02 -2.19967961e-01  2.06874986e-03 -3.78048480e-01]]\n",
      "\n",
      "  [[ 8.01851392e-01 -6.17460370e-01 -1.00000000e+00 -1.29957928e-03\n",
      "    -1.00000000e+00 -4.79524761e-01  3.70977446e-04 -6.33595586e-01\n",
      "     5.19499481e-01 -3.13044502e-03  4.36126254e-03 -1.91840734e-02\n",
      "    -1.63724005e-01 -4.19491649e-01 -5.34861445e-01 -2.75208980e-01\n",
      "     9.97080743e-01 -3.18151191e-02 -4.09200322e-03  1.67356484e-04\n",
      "    -3.32205564e-01  1.12239482e-04  1.67454317e-01  3.71151268e-01\n",
      "    -1.32677017e-03 -5.02570183e-05  2.02609211e-01  8.85691762e-01\n",
      "    -1.48651877e-03 -2.56558329e-01  4.63782735e-02  6.57288730e-02]]\n",
      "\n",
      "  [[ 7.60683358e-01 -3.98364633e-01 -3.26764828e-04 -2.08166032e-03\n",
      "    -1.00000000e+00  1.33488968e-01 -7.78298900e-02  4.74312284e-04\n",
      "    -5.91952819e-04  3.04343142e-02  3.84506255e-01 -2.26705536e-01\n",
      "    -2.47453004e-01  1.07675910e-01 -3.78141776e-02 -2.00852856e-01\n",
      "     1.00000000e+00  1.14010029e-01 -5.29588878e-01  1.34265780e-01\n",
      "    -3.36294174e-01 -2.31009975e-01  1.34500876e-01  2.51987457e-01\n",
      "    -4.39381272e-01  3.54461446e-02  1.07068785e-01 -1.93076700e-01\n",
      "     1.25565028e-04  3.86089720e-02  3.11152667e-01  1.35493144e-01]]]\n",
      "\n",
      "\n",
      " [[[ 5.00365555e-01 -2.89103419e-01  1.64821327e-01 -4.06095773e-01\n",
      "    -9.65899825e-01 -5.50052756e-03  7.75254071e-01 -3.44212807e-04\n",
      "     9.50746477e-01 -3.42897207e-01  1.00000000e+00  5.74955670e-03\n",
      "     3.64997834e-01  2.92189658e-01 -1.62879024e-02 -1.43116096e-03\n",
      "     2.24039540e-01  2.37843975e-01  5.59448659e-01  7.26695538e-01\n",
      "     7.75897279e-02  1.00000000e+00  4.40587383e-03 -4.94758964e-01\n",
      "     4.52097774e-01  6.32905722e-01  4.76655848e-02 -1.69615373e-01\n",
      "    -2.21742243e-01  4.50242870e-03  1.28336833e-05 -9.82997537e-01]]\n",
      "\n",
      "  [[ 8.09123635e-01 -7.08181500e-01 -8.33905876e-01 -2.75051713e-01\n",
      "    -9.76679683e-01 -1.00000000e+00  5.59680521e-01 -9.44298446e-01\n",
      "     8.05344939e-01 -4.37145919e-01  9.99824584e-01 -1.98772565e-01\n",
      "     9.97910321e-01 -4.97318149e-01 -3.75218034e-01 -2.76819716e-04\n",
      "     3.89444709e-01 -5.11625898e-04  4.71422195e-01  7.64775395e-01\n",
      "    -6.53316325e-04  5.21759331e-01 -1.02901617e-02 -2.08781451e-01\n",
      "     2.24781185e-01  3.17533970e-01  3.47900204e-03  4.39054340e-01\n",
      "     1.76957518e-01 -2.02763081e-03 -3.31082880e-01 -2.79477566e-01]]\n",
      "\n",
      "  [[ 7.98530579e-02 -7.80189782e-03 -9.99965370e-01 -3.12644541e-01\n",
      "    -9.00626779e-01 -3.48039786e-04  5.35762229e-04 -1.77858964e-01\n",
      "     1.59124355e-03 -1.92993477e-01  9.97082949e-01 -6.15254827e-02\n",
      "     1.16749898e-01 -1.21874116e-01 -7.87054479e-01  2.57338639e-02\n",
      "     2.63243914e-01 -5.41127980e-01  9.89056751e-02  7.53969431e-01\n",
      "    -6.97970681e-04  4.03575227e-03 -9.63679627e-02  2.49455171e-03\n",
      "     7.94465020e-02  2.50656396e-01  2.22881255e-03  9.17076170e-01\n",
      "     1.75611302e-01  1.63979858e-01 -2.06199974e-01  1.03233077e-01]]\n",
      "\n",
      "  [[ 2.73231271e-05  4.64445241e-02  7.95674250e-02 -3.29153568e-01\n",
      "    -7.95682251e-01  2.42866367e-01 -1.49583325e-01  1.40883520e-01\n",
      "    -1.22781537e-01 -4.83969510e-01  1.00000000e+00 -2.11946756e-01\n",
      "     2.83004338e-05  8.31798390e-02 -5.89816868e-01  4.55759130e-02\n",
      "     1.54253602e-01 -2.46751718e-02 -4.08563554e-01  9.99745131e-01\n",
      "     2.69686449e-02 -1.50721565e-01 -1.23013943e-01 -4.77764243e-03\n",
      "    -2.34943286e-01  8.41638327e-01 -3.69413614e-01 -6.75289482e-02\n",
      "     2.73874164e-01  3.66619647e-01 -1.45899167e-03  1.12509038e-02]]]\n",
      "\n",
      "\n",
      " [[[ 9.99695241e-01 -3.68971169e-01  5.24030183e-04 -9.00048316e-01\n",
      "     2.15782871e-04 -7.77082622e-01  9.99926329e-01 -4.53835756e-01\n",
      "     9.99688148e-01 -8.50589931e-01  8.01737785e-01  1.78737924e-01\n",
      "    -3.46698910e-01 -1.35247484e-01  3.64582002e-01  1.68086018e-03\n",
      "     1.54849549e-03  4.56189603e-01  4.84917730e-01  1.00000000e+00\n",
      "     2.14449555e-01  8.80370975e-01 -2.24731043e-01 -4.19637948e-01\n",
      "     9.22183990e-01  9.99758363e-01 -2.16826588e-01 -3.59547079e-01\n",
      "     2.37825327e-02  4.86925483e-01 -3.04884285e-01 -3.70285213e-01]]\n",
      "\n",
      "  [[ 3.96777868e-01 -2.56908266e-03 -9.45286870e-01 -5.73661387e-01\n",
      "     4.89298534e-03 -8.27078104e-01  5.59594810e-01 -6.76700473e-01\n",
      "     5.32747865e-01 -6.09395266e-01  4.45635132e-02 -3.20438743e-02\n",
      "    -9.74309572e-04 -3.53192955e-01  5.31535000e-02  2.36072503e-02\n",
      "    -2.02635434e-04  2.40064800e-01  1.74671665e-01  9.99176383e-01\n",
      "     1.50521904e-01  5.33828914e-01 -2.10759908e-01 -4.59598184e-01\n",
      "     3.66469592e-01  8.67131889e-01 -2.24204496e-01  3.70964743e-02\n",
      "     2.41068937e-03  3.89009804e-01 -3.25055718e-01 -6.78848475e-03]]\n",
      "\n",
      "  [[ 5.43779461e-04  1.80968031e-01 -8.61735642e-01 -3.55370075e-01\n",
      "     2.09480543e-02 -7.80675281e-03  4.53245174e-03 -1.71611860e-01\n",
      "    -7.11245637e-04 -2.17523292e-01  1.32841155e-01 -5.49536645e-01\n",
      "     1.36981800e-01 -1.77149894e-03  7.55928282e-04  6.33329852e-03\n",
      "    -2.05167104e-03 -9.54059069e-04 -6.42251670e-02  4.84341234e-02\n",
      "     1.53993547e-01  7.71649629e-02 -2.42544144e-01 -1.29996702e-01\n",
      "    -1.10478583e-03  8.83991942e-02 -3.12298745e-01  1.84337348e-01\n",
      "     4.68647070e-02  3.25622410e-01 -3.22146863e-01 -1.13531249e-03]]\n",
      "\n",
      "  [[-2.27944538e-01  1.57941803e-01 -3.55908042e-03 -6.73612237e-01\n",
      "     2.90598418e-05  2.01534793e-01 -1.68380663e-01  6.92527890e-02\n",
      "    -3.77427459e-01 -7.89201140e-01  7.61801183e-01 -6.66502237e-01\n",
      "     5.21732032e-01  5.24976812e-02 -2.95688212e-01  9.70050751e-05\n",
      "    -1.81246355e-01 -3.37445706e-01 -2.50778645e-01  4.33215141e-01\n",
      "     3.88350375e-02 -7.91053101e-03 -1.80070277e-03 -1.77431643e-01\n",
      "    -1.19543448e-01  5.38894475e-01 -5.54719627e-01  4.83281538e-03\n",
      "     4.08870101e-01  3.75077277e-02 -2.27004647e-01 -9.25576314e-02]]]]\n",
      "[[[[-7.83038810e-02 -5.35435276e-03  1.37595847e-01 ...  7.02067763e-02\n",
      "     3.94418746e-01  4.54795480e-01]\n",
      "   [-1.28331169e-01  4.63107713e-02 -7.16406554e-02 ... -4.24998216e-02\n",
      "     7.91746080e-02  8.81712735e-02]\n",
      "   [ 7.10929930e-02  7.08707422e-03 -1.14012495e-01 ...  1.51843071e-01\n",
      "    -1.12641174e-02 -1.24042019e-01]\n",
      "   ...\n",
      "   [ 2.42673054e-01  1.89838372e-03 -7.32692257e-02 ...  6.72054198e-03\n",
      "    -8.33525555e-05 -2.09844753e-01]\n",
      "   [-1.53939754e-01  1.70570806e-01  4.08810154e-02 ...  4.97528426e-02\n",
      "    -2.95618214e-02  1.56861976e-01]\n",
      "   [ 1.97994560e-01  1.47888154e-01 -1.83430567e-01 ...  4.49029021e-02\n",
      "    -1.13453716e-01 -7.33407512e-02]]\n",
      "\n",
      "  [[ 5.42319529e-02 -1.31565407e-01  4.02291398e-03 ...  1.14848148e-02\n",
      "     5.75722516e-01  3.42880011e-01]\n",
      "   [-2.34173820e-03  1.22861929e-01  6.65559014e-03 ... -1.78686589e-01\n",
      "     1.46793725e-03  2.42458284e-01]\n",
      "   [ 6.15331484e-03 -6.44869357e-02 -1.61900282e-01 ...  5.68179674e-02\n",
      "    -1.19671859e-01 -3.02618481e-02]\n",
      "   ...\n",
      "   [ 4.92128357e-03 -1.06348962e-01  6.66710967e-03 ... -1.15366420e-03\n",
      "     4.74827969e-03 -8.74682739e-02]\n",
      "   [ 8.60354453e-02 -3.08529958e-02  7.73871224e-03 ...  4.55796486e-03\n",
      "     6.96282787e-03  3.89444530e-02]\n",
      "   [-3.81219154e-03 -3.97222862e-02 -1.15599647e-01 ...  1.05634570e-01\n",
      "     4.75633405e-02 -3.16712707e-02]]\n",
      "\n",
      "  [[-1.34585187e-01 -1.03649296e-01  7.58847296e-02 ...  1.11564264e-01\n",
      "     6.31336451e-01  2.34784171e-01]\n",
      "   [ 8.05782601e-02 -1.66803710e-02  1.54567793e-01 ...  1.12006720e-02\n",
      "    -4.32021677e-01 -2.60842256e-02]\n",
      "   [ 7.77647719e-02 -1.98204725e-04 -8.46926719e-02 ...  1.98405907e-02\n",
      "    -3.48929405e-01  4.55754697e-02]\n",
      "   ...\n",
      "   [-3.37472633e-02  1.20855570e-01  2.39893738e-02 ... -3.11052962e-03\n",
      "     1.67123172e-02  1.26317618e-02]\n",
      "   [ 2.32915848e-01 -2.18917578e-02  6.60991855e-03 ...  6.48693070e-02\n",
      "     8.26526061e-02 -1.88489389e-02]\n",
      "   [ 2.19383131e-04 -9.65589881e-02 -1.06923372e-01 ...  8.31665173e-02\n",
      "    -5.57779595e-02 -3.54112685e-03]]]\n",
      "\n",
      "\n",
      " [[[-5.83136594e-03  3.25133256e-03 -3.53933731e-03 ...  1.45387918e-01\n",
      "     3.28517258e-01  4.09600258e-01]\n",
      "   [-5.54911196e-02  1.04047187e-01 -2.83303745e-02 ...  1.71832480e-02\n",
      "     6.68157190e-02 -9.49956104e-03]\n",
      "   [-4.05279547e-02  1.35192666e-02  1.19388260e-01 ...  1.52380109e-01\n",
      "     1.31513044e-01 -2.11973384e-06]\n",
      "   ...\n",
      "   [ 2.72887312e-02  4.09664679e-03  3.37917581e-02 ...  4.91691418e-02\n",
      "     4.83766757e-02  2.61736047e-02]\n",
      "   [ 9.82737634e-03  1.28708020e-01 -6.75245281e-03 ...  7.75228217e-02\n",
      "     1.05861924e-04  1.43619515e-02]\n",
      "   [ 1.32481372e-02  3.49139310e-02  5.43399528e-02 ... -2.58464888e-02\n",
      "     4.43248563e-02  8.26258138e-02]]\n",
      "\n",
      "  [[ 1.08633377e-03 -2.29575094e-02 -1.02328785e-01 ...  1.15962610e-01\n",
      "     3.61517310e-01  3.34024876e-01]\n",
      "   [-4.30140831e-02  5.36345243e-02 -6.01517083e-03 ...  1.81545387e-03\n",
      "    -2.98667867e-02 -9.07238275e-02]\n",
      "   [-2.49250010e-02 -4.50634025e-02 -4.51348387e-02 ...  3.64701860e-02\n",
      "    -1.99458953e-02  1.34622619e-01]\n",
      "   ...\n",
      "   [-6.09315671e-02  3.41345072e-02  2.61538681e-02 ...  5.34323566e-02\n",
      "     3.74613656e-03  1.23925090e-01]\n",
      "   [ 3.03230453e-02 -4.82625514e-02 -8.84320065e-02 ... -9.59141925e-02\n",
      "     1.24325240e-02 -2.52748001e-03]\n",
      "   [ 2.23612022e-02 -1.25626266e-01  3.01945936e-02 ...  3.46732624e-02\n",
      "     2.46543288e-02  6.18199371e-02]]\n",
      "\n",
      "  [[-6.16432168e-02  1.74318824e-03  1.66116108e-04 ...  7.62853324e-02\n",
      "     4.13223743e-01  1.10581271e-01]\n",
      "   [-1.08180515e-01  3.98711562e-02 -8.19193572e-03 ... -6.87079430e-02\n",
      "     3.15155085e-05 -5.17558195e-02]\n",
      "   [ 1.25550315e-01  6.25859499e-02 -4.96393144e-02 ...  8.85363445e-02\n",
      "    -1.03320710e-01  7.52254575e-02]\n",
      "   ...\n",
      "   [-4.28036787e-02  1.53835090e-02  1.03211896e-02 ...  1.25736478e-04\n",
      "    -5.42031042e-02  6.01196922e-02]\n",
      "   [ 1.75146565e-01 -8.81243497e-02  7.56977545e-03 ...  6.24116436e-02\n",
      "     1.62624285e-01 -1.14066429e-01]\n",
      "   [ 1.35702442e-03 -5.58747835e-02  3.29890661e-02 ...  2.02440143e-01\n",
      "    -6.27685804e-03  1.09116592e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.96069922e-02 -1.20787568e-01 -1.54974937e-01 ...  2.83070486e-02\n",
      "     5.20806491e-01  2.62192905e-01]\n",
      "   [ 1.05136679e-02 -3.05473842e-02 -7.71999732e-02 ...  2.99032517e-02\n",
      "    -2.49257341e-01 -2.80921906e-01]\n",
      "   [-2.98228804e-02 -6.20541014e-02  1.59344971e-01 ...  3.08260359e-02\n",
      "    -1.60153270e-01  2.99052522e-02]\n",
      "   ...\n",
      "   [ 2.83618830e-02  4.54364624e-03 -1.33172274e-01 ... -9.43874419e-02\n",
      "     2.20723525e-02  2.20147103e-01]\n",
      "   [-3.84843210e-03 -5.50546730e-03  1.68355554e-01 ...  2.42437329e-03\n",
      "     3.39762517e-03 -2.98636388e-02]\n",
      "   [-6.88478425e-02  1.42575577e-01  2.56455541e-01 ... -4.45055850e-02\n",
      "    -2.21266467e-02  2.21827731e-01]]\n",
      "\n",
      "  [[-2.50578560e-02 -1.17848665e-01 -2.71002382e-01 ...  1.39062405e-02\n",
      "     3.85907412e-01  1.91248327e-01]\n",
      "   [-5.54318447e-03  6.25855057e-03  1.20781194e-02 ...  6.05117902e-02\n",
      "    -7.23543465e-02 -1.90144733e-01]\n",
      "   [-2.33684313e-02 -3.25402897e-03  1.78130805e-01 ... -6.17480949e-02\n",
      "    -8.83672833e-02  1.60886660e-01]\n",
      "   ...\n",
      "   [ 4.67307456e-02 -4.67298031e-02 -8.20960775e-02 ... -3.16508971e-02\n",
      "     8.34709033e-03  1.98806822e-01]\n",
      "   [-1.95734501e-02  9.67529323e-03  2.50387308e-03 ... -3.42881074e-03\n",
      "     4.30247374e-02 -5.00269681e-02]\n",
      "   [ 5.06211147e-02 -1.06740445e-01  2.16800660e-01 ... -3.60167259e-03\n",
      "    -5.99903949e-02  1.31727368e-01]]\n",
      "\n",
      "  [[-8.84007942e-03 -6.91334009e-02 -2.23527148e-01 ...  1.23477630e-01\n",
      "     2.94147700e-01  2.43703015e-02]\n",
      "   [-3.74895483e-02  1.46835104e-01 -1.26695149e-02 ...  5.53398021e-03\n",
      "     3.46263796e-02 -9.92335454e-02]\n",
      "   [ 1.72196596e-03 -1.17658630e-01  1.80821255e-01 ... -1.56293139e-02\n",
      "    -3.14035006e-02  2.82386560e-02]\n",
      "   ...\n",
      "   [ 2.32427759e-04 -6.80391192e-02 -1.72764808e-01 ... -2.62036115e-01\n",
      "    -5.35568409e-02  2.54814267e-01]\n",
      "   [ 3.85823287e-02  1.93898767e-01  1.22566521e-02 ...  2.25238129e-02\n",
      "     1.37638643e-01 -1.62434187e-02]\n",
      "   [ 4.25709732e-04 -2.02126250e-01  2.39139467e-01 ...  9.23855826e-02\n",
      "     5.95850162e-02  2.13681236e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "for idx, weights in enumerate(conv_weights):\n",
    "    for w in weights:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 1.,  1.,  1., ..., -1., -1.,  1.],\n",
      "        [-1.,  1.,  1., ...,  1.,  1., -1.],\n",
      "        [ 1.,  1., -1., ...,  1., -1.,  1.],\n",
      "        ...,\n",
      "        [-1.,  1., -1., ...,  1., -1., -1.],\n",
      "        [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
      "        [-1., -1., -1., ..., -1., -1.,  1.]]], dtype=float32), array([[[ 1., -1., -1., ..., -1.,  1., -1.],\n",
      "        [ 1., -1.,  1., ..., -1.,  1.,  1.],\n",
      "        [ 1., -1., -1., ...,  1., -1.,  1.],\n",
      "        ...,\n",
      "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
      "        [-1.,  1., -1., ..., -1., -1.,  1.],\n",
      "        [ 1., -1.,  1., ..., -1., -1.,  1.]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "QD_weights = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, lq.layers.QuantDense):\n",
    "        weights = layer.get_weights()  \n",
    "        QD_weights.append(weights)\n",
    "\n",
    "binarized_weights = []\n",
    "binarized_weight = [np.sign(w) for w in QD_weights]\n",
    "binarized_weights.append(binarized_weight)\n",
    "\n",
    "for w in binarized_weights:\n",
    "    print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 1.2364 - accuracy: 0.6926\n",
      "+sequential stats-----------------------------------------------------------------------------+\n",
      "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs |\n",
      "|                              (bit)                        x 1       x 1    (kB)             |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d                     1  (-1, 25, 25, 32)      512         0    0.06      320000 |\n",
      "| batch_normalization              -  (-1, 25, 25, 32)        0        64    0.25           0 |\n",
      "| quant_conv2d_1                   1  (-1, 23, 23, 32)     9216         0    1.12     4875264 |\n",
      "| batch_normalization_1            -  (-1, 23, 23, 32)        0        64    0.25           0 |\n",
      "| flatten                          -       (-1, 16928)        0         0       0           0 |\n",
      "| quant_dense                      1         (-1, 128)  2166784         0  264.50     2166784 |\n",
      "| batch_normalization_2            -         (-1, 128)        0       256    1.00           0 |\n",
      "| quant_dense_1                    1          (-1, 10)     1280         0    0.16        1280 |\n",
      "| batch_normalization_3            -          (-1, 10)        0        20    0.08           0 |\n",
      "| activation                       -          (-1, 10)        0         0       0           ? |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "| Total                                                 2177792       404  267.42     7363328 |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "+sequential summary----------------------------+\n",
      "| Total params                      2.18 M     |\n",
      "| Trainable params                  2.18 M     |\n",
      "| Non-trainable params              404        |\n",
      "| Model size                        267.42 KiB |\n",
      "| Model size (8-bit FP weights)     266.24 KiB |\n",
      "| Float-32 Equivalent               8.31 MiB   |\n",
      "| Compression Ratio of Memory       0.03       |\n",
      "| Number of MACs                    7.36 M     |\n",
      "| Ratio of MACs that are binarized  1.0000     |\n",
      "+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Train NN\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "lq.models.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract weights\n",
    "# with lq.context.quantized_scope(True):\n",
    "#     weights = model.layers[3].get_weights()\n",
    "#     print(weights)\n",
    "\n",
    "#     if len(weights) > 0:\n",
    "#         weight_array = weights[0] \n",
    "#         print(\"Weights shape:\", weight_array.shape)\n",
    "#     else:\n",
    "#         print(\"No weights found in this layer.\")\n",
    "\n",
    "# print(weights[0].shape)\n",
    "# rows, cols, _, output_channels = weights[0].shape\n",
    "# print(rows, cols, output_channels)\n",
    "# for col in range(cols):\n",
    "#     for row in range(rows):\n",
    "#         for output_channel in range(output_channels):\n",
    "#             print(row, col, output_channel, weights[0][row][col][0][output_channel])\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#         beta, moving_mean, moving_variance = layer.get_weights()\n",
    "#         print(f\"Layer: {layer.name}\")\n",
    "#         print(f\"  Beta (offset): {beta}\")\n",
    "#         print(f\"Beta Length: {len(beta)}\")\n",
    "#         print(f\"  Moving Mean: {moving_mean}\")\n",
    "#         print(f\" Moving Mean Length: {len(moving_mean)}\")\n",
    "#         print(f\"  Moving Variance: {moving_variance}\")\n",
    "#         print(f\"  Moving Variance Length: {len(moving_variance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: batch_normalization, Input shape: (None, 25, 25, 32)\n",
      "Layer: batch_normalization_1, Input shape: (None, 23, 23, 32)\n",
      "Layer: batch_normalization_2, Input shape: (None, 128)\n",
      "Layer: batch_normalization_3, Input shape: (None, 10)\n"
     ]
    }
   ],
   "source": [
    "input_shape_callback = InputShapeCallback()\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        input_shape = layer.input_shape\n",
    "        print(f\"Layer: {layer.name}, Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"gen_hdl\"):\n",
    "    os.mkdir(\"gen_hdl\")\n",
    "\n",
    "# Extract weights\n",
    "betas = []\n",
    "moving_means = []\n",
    "moving_variances = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        beta, moving_mean, moving_variance = layer.get_weights()\n",
    "        betas.append(beta)\n",
    "        moving_means.append(moving_mean)\n",
    "        moving_variances.append(moving_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bn(beta, moving_mean, moving_variance, num: int):\n",
    "\n",
    "    # thresholds = np.zeros(len(beta))\n",
    "    compare = \"\"\n",
    "    for output_neuron in range(len(beta)):\n",
    "        # print(len(beta))\n",
    "        threshold = moving_mean[output_neuron] - beta[output_neuron] * np.sqrt(moving_variance[output_neuron])\n",
    "        compare += f\"   assign o_data[{output_neuron}] = i_data[{output_neuron}] > {threshold} ? 1 : 0;\\n\"\n",
    "\n",
    "    output_hdl = templates.BN_TEMPLATE \\\n",
    "        .replace(\"%DIM_DATA%\", str(len(beta))) \\\n",
    "        .replace(\"%LAYER_NUM%\", str(num)) \\\n",
    "        .replace(\"%COMPARE%\", compare)\n",
    "        \n",
    "    with open(f\"gen_hdl/bn_layer_{num}.v\", \"w\") as f:\n",
    "        f.write(output_hdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(betas)):\n",
    "    parse_bn(betas[n], moving_means[n], moving_variances[n], n)\n",
    "\n",
    "weights = model.layers[0].get_weights()\n",
    "w = weights[0].reshape(16, 1, 32)\n",
    "print(w.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method QuantizedVariable.from_variable of <class 'larq.quantized_variable.QuantizedVariable'>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <gast.gast.Expr object at 0x0000022DCA2FE310>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method QuantizedVariable.from_variable of <class 'larq.quantized_variable.QuantizedVariable'>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <gast.gast.Expr object at 0x0000022DCA2FE310>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/6\n",
      "938/938 [==============================] - 6s 4ms/step - loss: 0.8717 - accuracy: 0.8202\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.7025 - accuracy: 0.8741\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.6871 - accuracy: 0.8796\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.6814 - accuracy: 0.8788\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.6751 - accuracy: 0.8827\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.6692 - accuracy: 0.8825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22dca700040>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrunableQuantDense(lq.layers.QuantDense, sparsity.PrunableLayer):\n",
    "    def get_prunable_weights(self):\n",
    "        return [self.kernel]\n",
    "\n",
    "pruning_params = {\n",
    "    'pruning_schedule': sparsity.PolynomialDecay(\n",
    "        initial_sparsity=0.0,\n",
    "        final_sparsity=0.5,\n",
    "        begin_step=0,\n",
    "        end_step=len(train_images) // 64 * 6\n",
    "    )\n",
    "}\n",
    "\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\")\n",
    "\n",
    "model_new = tf.keras.models.Sequential()\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model_new.add(tf.keras.layers.Flatten(input_shape=input_shape))\n",
    "\n",
    "# 128 neurons\n",
    "model_new.add(sparsity.prune_low_magnitude(PrunableQuantDense(128, use_bias=False, **kwargs), **pruning_params))\n",
    "model_new.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# 128 neurons\n",
    "model_new.add(sparsity.prune_low_magnitude(PrunableQuantDense(128, use_bias=False, **kwargs), **pruning_params))\n",
    "model_new.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# 64 neurons\n",
    "model_new.add(sparsity.prune_low_magnitude(PrunableQuantDense(64, use_bias=False, **kwargs), **pruning_params))\n",
    "model_new.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "# 10 neurons\n",
    "model_new.add(sparsity.prune_low_magnitude(PrunableQuantDense(10, use_bias=False, **kwargs), **pruning_params))\n",
    "model_new.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_new.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model_new.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_new.fit(train_images, train_labels,\n",
    "              batch_size=64, epochs=6,\n",
    "              callbacks=[sparsity.UpdatePruningStep()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.5945 - accuracy: 0.9041\n",
      "Stripped Pruned Model Test Loss: 0.5945272445678711\n",
      "Stripped Pruned Model Test Accuracy: 0.9041000008583069\n",
      "+sequential_1 stats---------------------------------------------------------------------+\n",
      "| Layer                   Input prec.    Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs |\n",
      "|                               (bit)                 x 1       x 1    (kB)             |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| flatten_1                         -  (-1, 784)        0         0       0           0 |\n",
      "| prunable_quant_dense              1  (-1, 128)   100352         0   12.25      100352 |\n",
      "| batch_normalization_4             -  (-1, 128)        0       256    1.00           0 |\n",
      "| prunable_quant_dense_1            1  (-1, 128)    16384         0    2.00       16384 |\n",
      "| batch_normalization_5             -  (-1, 128)        0       256    1.00           0 |\n",
      "| prunable_quant_dense_2            1   (-1, 64)     8192         0    1.00        8192 |\n",
      "| batch_normalization_6             -   (-1, 64)        0       128    0.50           0 |\n",
      "| prunable_quant_dense_3            1   (-1, 10)      640         0    0.08         640 |\n",
      "| batch_normalization_7             -   (-1, 10)        0        20    0.08           0 |\n",
      "| activation_1                      -   (-1, 10)        0         0       0           ? |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Total                                            125568       660   17.91      125568 |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "+sequential_1 summary--------------------------+\n",
      "| Total params                      126 k      |\n",
      "| Trainable params                  126 k      |\n",
      "| Non-trainable params              660        |\n",
      "| Model size                        17.91 KiB  |\n",
      "| Model size (8-bit FP weights)     15.97 KiB  |\n",
      "| Float-32 Equivalent               493.08 KiB |\n",
      "| Compression Ratio of Memory       0.04       |\n",
      "| Number of MACs                    126 k      |\n",
      "| Ratio of MACs that are binarized  1.0000     |\n",
      "+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_model = tfmot.sparsity.keras.strip_pruning(model_new)\n",
    "final_model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "final_test_loss, final_test_accuracy = final_model.evaluate(test_images, test_labels)\n",
    "print(f'Stripped Pruned Model Test Loss: {final_test_loss}')\n",
    "print(f'Stripped Pruned Model Test Accuracy: {final_test_accuracy}')\n",
    "lq.models.summary(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 1.8514 - accuracy: 0.7731\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.1739 - accuracy: 0.8497\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.0711 - accuracy: 0.8677\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.9749 - accuracy: 0.8790\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.9417 - accuracy: 0.8867\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.9043 - accuracy: 0.8917\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_11 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " quant_dense_38 (QuantDense  (None, 128)               100352    \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 128)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_dense_39 (QuantDense  (None, 128)               16384     \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 128)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_dense_40 (QuantDense  (None, 64)                8192      \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 64)                192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " quant_dense_41 (QuantDense  (None, 10)                640       \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126528 (494.25 KB)\n",
      "Trainable params: 125888 (491.75 KB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fc = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "input_shape = (28, 28, 1)  \n",
    "\n",
    "\n",
    "model_fc.add(tf.keras.layers.Flatten(input_shape=input_shape))\n",
    "\n",
    "\n",
    "model_fc.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "model_fc.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_fc.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "model_fc.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_fc.add(lq.layers.QuantDense(64, use_bias=False, **kwargs))\n",
    "model_fc.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_fc.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "# model_fc.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model_fc.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model_fc.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_fc.fit(train_images, train_labels, batch_size=64, epochs=6)\n",
    "\n",
    "model_fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.8969 - accuracy: 0.8922\n",
      "+sequential_11 stats--------------------------------------------------------------------+\n",
      "| Layer                   Input prec.    Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs |\n",
      "|                               (bit)                 x 1       x 1    (kB)             |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| flatten_11                        -  (-1, 784)        0         0       0           0 |\n",
      "| quant_dense_38                    1  (-1, 128)   100352         0   12.25      100352 |\n",
      "| batch_normalization_37            -  (-1, 128)        0       256    1.00           0 |\n",
      "| quant_dense_39                    1  (-1, 128)    16384         0    2.00       16384 |\n",
      "| batch_normalization_38            -  (-1, 128)        0       256    1.00           0 |\n",
      "| quant_dense_40                    1   (-1, 64)     8192         0    1.00        8192 |\n",
      "| batch_normalization_39            -   (-1, 64)        0       128    0.50           0 |\n",
      "| quant_dense_41                    1   (-1, 10)      640         0    0.08         640 |\n",
      "| activation_11                     -   (-1, 10)        0         0       0           ? |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Total                                            125568       640   17.83      125568 |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "+sequential_11 summary-------------------------+\n",
      "| Total params                      126 k      |\n",
      "| Trainable params                  126 k      |\n",
      "| Non-trainable params              640        |\n",
      "| Model size                        17.83 KiB  |\n",
      "| Model size (8-bit FP weights)     15.95 KiB  |\n",
      "| Float-32 Equivalent               493.00 KiB |\n",
      "| Compression Ratio of Memory       0.04       |\n",
      "| Number of MACs                    126 k      |\n",
      "| Ratio of MACs that are binarized  1.0000     |\n",
      "+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_fc.evaluate(test_images, test_labels)\n",
    "lq.models.summary(model_fc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
