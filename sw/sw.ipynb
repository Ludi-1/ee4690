{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import larq as lq\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def print_image(image):\n",
    "  # Squeeze the third dimension or you can use indexing to select the first slice\n",
    "  image_2d = np.squeeze(image)\n",
    "\n",
    "  # Plotting the image\n",
    "  plt.imshow(image_2d, cmap='gray')  # Use the gray colormap for grayscale\n",
    "  plt.colorbar()  # Optionally add a colorbar to see the intensity scale\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "print_image(train_images[0])\n",
    "# Normalize pixel values to be between -1 and 1\n",
    "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputShapeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.input_shapes = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                input_shape = layer.input_shape\n",
    "                self.input_shapes.append((layer.name, input_shape))\n",
    "                print(f\"Layer: {layer.name}, Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6544 - accuracy: 0.9087\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.5002 - accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.4765 - accuracy: 0.9638\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.4641 - accuracy: 0.9679\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.4588 - accuracy: 0.9691\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.4560 - accuracy: 0.9704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2694bf02730>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN Topology\n",
    "\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "input_shape = (28, 28, 1) # Input img shape\n",
    "filters_a = 32 # Number of output channels\n",
    "kernel_three = (4, 4) # Kernel dimension\n",
    "\n",
    "filters_b = 32 # Number of output channels\n",
    "kernel_b = (3, 3) # Kernel dimension\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(filters_a, kernel_three,\n",
    "                                input_quantizer=\"ste_sign\",\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(lq.layers.QuantConv2D(filters_b, kernel_b,\n",
    "                                input_quantizer=\"ste_sign\",\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# # model.add(lq.layers.QuantDense(500, use_bias=False, **kwargs))\n",
    "# model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "# model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, batch_size=64, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.4991 - accuracy: 0.9654\n",
      "+sequential stats-----------------------------------------------------------------------------+\n",
      "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs |\n",
      "|                              (bit)                        x 1       x 1    (kB)             |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d                     1  (-1, 25, 25, 32)      512         0    0.06      320000 |\n",
      "| max_pooling2d                    -  (-1, 12, 12, 32)        0         0       0           0 |\n",
      "| batch_normalization              -  (-1, 12, 12, 32)        0        64    0.25           0 |\n",
      "| quant_conv2d_1                   1  (-1, 10, 10, 32)     9216         0    1.12      921600 |\n",
      "| max_pooling2d_1                  -    (-1, 5, 5, 32)        0         0       0           0 |\n",
      "| batch_normalization_1            -    (-1, 5, 5, 32)        0        64    0.25           0 |\n",
      "| flatten                          -         (-1, 800)        0         0       0           0 |\n",
      "| quant_dense                      1         (-1, 128)   102400         0   12.50      102400 |\n",
      "| batch_normalization_2            -         (-1, 128)        0       256    1.00           0 |\n",
      "| quant_dense_1                    1          (-1, 10)     1280         0    0.16        1280 |\n",
      "| batch_normalization_3            -          (-1, 10)        0        20    0.08           0 |\n",
      "| activation                       -          (-1, 10)        0         0       0           ? |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "| Total                                                  113408       404   15.42     1345280 |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "+sequential summary----------------------------+\n",
      "| Total params                      114 k      |\n",
      "| Trainable params                  113 k      |\n",
      "| Non-trainable params              404        |\n",
      "| Model size                        15.42 KiB  |\n",
      "| Model size (8-bit FP weights)     14.24 KiB  |\n",
      "| Float-32 Equivalent               444.58 KiB |\n",
      "| Compression Ratio of Memory       0.03       |\n",
      "| Number of MACs                    1.35 M     |\n",
      "| Ratio of MACs that are binarized  1.0000     |\n",
      "+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Train NN\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "lq.models.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: batch_normalization\n",
      "  Beta (offset): [-1.21813387e-01 -1.74739093e-01 -3.27783704e-01  3.53027374e-01\n",
      " -1.09255242e+00 -4.05520260e-01  1.23358555e-01 -5.96586466e-01\n",
      " -3.25887538e-02 -3.79818141e-01 -5.47126353e-01 -2.57174820e-01\n",
      " -6.04369998e-01 -2.64586866e-01 -1.79705843e-01 -3.04063648e-01\n",
      " -4.31858480e-01 -3.76465261e-01 -1.59128517e-01 -6.15197718e-01\n",
      " -8.05432796e-02 -1.32059276e-01 -2.39873856e-01 -1.01554184e-03\n",
      " -2.99865395e-01 -2.93905109e-01 -3.60132843e-01 -1.85029775e-01\n",
      " -2.78929770e-01 -1.63783237e-01 -3.55082840e-01 -5.18926561e-01]\n",
      "Beta Length: 32\n",
      "  Moving Mean: [ 3.460862   -0.71490407  2.9112906  -1.381075    1.9508567   0.7135684\n",
      " -0.93062854  5.286661   -2.8647237   3.2657008   4.2312403   6.22665\n",
      "  3.9604487   4.159044   -2.6283598   5.67221     3.1019099   6.096448\n",
      "  1.1206907   5.7346344  -3.0208535  -1.7929711   4.122885    1.578727\n",
      "  6.0405884   4.480065   -2.8120716   0.5694792   3.9332128   1.0884994\n",
      "  6.2638574   3.731975  ]\n",
      " Moving Mean Length: 32\n",
      "  Moving Variance: [11.800337  12.627874  13.693425  18.949272  14.762402   9.503696\n",
      " 15.677376  12.214937  21.232883  15.411038  12.96235   16.148394\n",
      " 14.168143  12.803321  22.227337  11.002668   6.810486  14.307659\n",
      "  7.1369557 14.450499  22.398977  23.571632   9.901106  13.849155\n",
      " 16.72648   14.6822405 25.334343  13.782672   5.9167333 11.460778\n",
      " 14.051074   8.1026745]\n",
      "  Moving Variance Length: 32\n",
      "Layer: batch_normalization_1\n",
      "  Beta (offset): [-0.27393267 -0.419364   -0.1930831  -0.15964597 -0.34300452 -0.36552835\n",
      " -0.5522111  -0.03289968 -0.50547194 -0.58215773 -0.43349758 -0.6857772\n",
      " -0.5997836  -0.4910762  -0.44362506 -0.5097262  -0.57617927 -0.13741209\n",
      "  0.09320605 -0.4168202  -0.81045127 -0.1892766  -0.335925   -0.12112929\n",
      "  0.19094886 -0.18173778 -0.21383521 -0.2747727   0.03589439 -0.20829505\n",
      " -0.20293209 -0.08510329]\n",
      "Beta Length: 32\n",
      "  Moving Mean: [-9.356971   5.2991724 15.280952  15.067196  28.161661  19.008507\n",
      "  3.3024087  6.402823  28.405277  25.436872  32.867027  14.460015\n",
      " 32.095192  17.848982   9.717607   7.998083  22.442396  30.1888\n",
      " 24.511274  22.7753     7.9673543 41.31455   16.169163  13.627699\n",
      " 21.637705  19.079884  24.719072  20.213099  17.44794   41.34862\n",
      " 29.21543    8.108728 ]\n",
      " Moving Mean Length: 32\n",
      "  Moving Variance: [ 740.6906   797.93475  661.4501   968.8822   944.8101   468.31674\n",
      "  664.7586  1246.9507   954.63446  603.8583   678.5523   825.9505\n",
      "  804.86804  559.3671   618.4527   674.2062   724.439   1059.1089\n",
      "  996.49225  820.1964   429.25085  832.0279  1307.6077  1042.0746\n",
      " 1049.6868   753.7035   607.36755  715.1341  1263.4465   775.26874\n",
      "  937.3876   676.806  ]\n",
      "  Moving Variance Length: 32\n",
      "Layer: batch_normalization_2\n",
      "  Beta (offset): [ 0.6135587  -0.17263949 -0.704951   -0.5579205  -0.52551275  0.08821207\n",
      "  0.23118964 -0.45271719  0.4452409  -0.29888123 -0.04179554  0.50854754\n",
      "  0.49347994 -0.24975392 -0.6426917   0.5434799   0.726707    0.21050705\n",
      "  0.4704977  -0.13627988 -0.59708077 -0.06239625  0.4655995   0.7751264\n",
      " -0.27409282  0.36753327 -0.85668415 -0.6847182  -0.32480332  0.58603644\n",
      "  0.6240698   0.04358044  0.7341354   0.24658804 -0.3108594  -0.5117627\n",
      "  0.2028373  -0.02100887 -0.5505977   0.3210065   0.63327575  0.3069243\n",
      "  0.6564897  -0.11275399  0.04445736 -0.31072778 -0.51582384 -0.4634625\n",
      "  0.4535227  -0.5346601   0.20384963 -0.5768576  -0.2191194  -0.40965334\n",
      "  0.94978136 -0.21804376 -0.4389307  -0.66649055  0.763362    0.06110271\n",
      "  0.55724674  0.2908638   0.5814034   0.67540663 -0.45337752  0.340836\n",
      "  0.12917097  0.86468035 -0.30076933  0.7655675   0.602675    0.398248\n",
      " -0.03128589 -0.48878357 -0.10876085  0.07335162 -0.733987    0.02336503\n",
      "  0.61182535  0.545036   -0.07009129 -0.6650561  -0.05300044  0.4860864\n",
      " -0.46382138 -0.37650704  0.33028206  0.22967635 -0.38706455  0.75557184\n",
      "  0.07420922  0.4984729  -0.0368094   0.28790274 -0.42698056 -0.45447692\n",
      " -0.5210337   0.46647474 -0.30991176 -0.05795601  0.8785741  -0.11056106\n",
      "  0.45714942  0.77052385 -0.3555241   0.77860004  0.1850306   0.5068059\n",
      "  0.42332006  0.8056224  -0.48829982  0.6680278   0.51478726  0.05529891\n",
      "  0.65160173  0.41460016 -0.20678668 -0.5452121  -0.19823681  0.338666\n",
      "  0.6837264  -0.69913447 -0.42828134  0.8042778  -0.8859454  -0.04416316\n",
      " -0.7684472   0.8838098 ]\n",
      "Beta Length: 128\n",
      "  Moving Mean: [-36.486885   -24.111391    11.278671    26.52262     13.489246\n",
      " -14.867469    -5.8212495   22.435501   -18.895262   -16.855387\n",
      " -26.842716   -58.510273   -24.366438   -31.534819    44.30927\n",
      " -28.11534      2.775253   -10.8016      24.26579    -20.989847\n",
      "   6.089465    14.18546     29.60069    -12.027364    -2.7131317\n",
      "  22.617035    54.45013     -4.271579   -25.732084    16.142952\n",
      " -49.49934    -34.50928    -23.345663   -33.04894     15.076772\n",
      "   9.391773    17.188429    39.44214      4.3918695  -25.766743\n",
      " -29.676933     4.1532164   33.20496     15.07408    -42.550243\n",
      " -37.151287   -18.836351     6.079251    27.99673     16.071169\n",
      "  20.743994    -5.391409    -4.2681136  -24.196255    20.239332\n",
      "   0.41985202 -21.853859    18.6199     -45.150204    23.907454\n",
      "  53.012535    -7.7550573  -30.025768    18.355001   -22.24646\n",
      "   8.31469      9.455882    19.60232      6.504961    49.58916\n",
      "  11.125409    51.120914   -23.72172    -58.509872    53.799946\n",
      "  -2.9580932   -9.980428   -12.198751    18.157091    -0.5963855\n",
      "   7.5927706    1.3104593   65.91839     -0.753587    -6.1233125\n",
      "  37.96275      9.1102      42.699116    14.151782    -6.380634\n",
      "  22.965488    15.996319   -21.333609    60.71808    -36.680122\n",
      " -25.367704    73.13826     13.561067     8.491322    48.249283\n",
      "   9.452491    76.13778    -25.79497    -72.00438     23.081015\n",
      " -22.10491     18.387924   -10.367215    21.05323     19.90509\n",
      "  13.900018    -8.09281      6.7249393  -53.249413   -10.3597145\n",
      "  -4.3800635   16.847612    59.8331       8.826978   -56.933613\n",
      " -17.940748    24.749851   -26.399155   -40.611244    31.948658\n",
      "  42.496872    10.773938     6.968999  ]\n",
      " Moving Mean Length: 128\n",
      "  Moving Variance: [3041.121  3415.3474 2358.8723 3921.213  3380.0955 2725.265  2792.9429\n",
      " 2374.8174 3436.0872 2424.881  2755.7876 2899.3296 3054.739  3288.1624\n",
      " 1956.0027 4675.7744 3467.5383 3951.5295 2356.3364 2936.6963 3156.7402\n",
      " 2400.7373 3194.8923 2933.8733 4469.104  2447.174  4966.234  3558.713\n",
      " 2476.8733 2611.985  2657.7773 2779.4216 4425.3374 2229.746  2274.7095\n",
      " 3436.617  2422.8872 3006.7446 2967.8247 2720.8445 3113.953  1977.4763\n",
      " 3129.304  2240.837  2318.1174 2275.8982 5165.5767 2216.0432 2907.3567\n",
      " 3243.5015 2937.8945 3167.5244 2467.0732 2902.0544 2586.0317 3379.1987\n",
      " 2471.08   3415.8035 2588.1648 2675.6914 3057.1099 2458.3916 2191.732\n",
      " 3884.0754 4123.6567 2285.0688 2726.194  2907.0261 2594.982  2362.2493\n",
      " 2831.725  2985.1445 2629.8362 3961.622  2764.8723 3354.7217 2541.3154\n",
      " 3405.9126 3129.378  3239.229  3649.447  3786.4521 2464.435  4012.5571\n",
      " 2555.1636 2910.6775 2120.8398 2717.3958 2595.8699 2762.2083 3004.4094\n",
      " 3071.662  2718.1948 2272.9028 3367.8389 2361.2505 1859.9819 3270.1497\n",
      " 3458.8352 3317.274  3433.7368 2998.1838 2833.4602 2432.175  2850.5667\n",
      " 2909.4084 2507.9412 3021.6948 2541.3354 3467.3843 4206.3345 3473.7498\n",
      " 2987.4102 3828.6863 3399.564  3193.8035 2872.4673 3813.7039 2720.8552\n",
      " 2569.2043 4363.4214 2877.065  4302.0547 3126.285  4579.0796 2255.5713\n",
      " 3031.537  4665.6953]\n",
      "  Moving Variance Length: 128\n",
      "Layer: batch_normalization_3\n",
      "  Beta (offset): [-0.0194212   0.1382183  -0.01981046  0.03357881 -0.03305692 -0.12772654\n",
      " -0.02205664  0.05873444 -0.03254269  0.00109715]\n",
      "Beta Length: 10\n",
      "  Moving Mean: [ 2.8319182  4.9881625  1.5440544  6.4107184  3.1049328  3.7863858\n",
      " -7.249546  -3.5400429  9.977884   2.5171556]\n",
      " Moving Mean Length: 10\n",
      "  Moving Variance: [790.5803  891.88513 651.9829  689.28424 695.1852  634.3015  756.4838\n",
      " 655.45245 574.57623 581.3483 ]\n",
      "  Moving Variance Length: 10\n"
     ]
    }
   ],
   "source": [
    "# # Extract weights\n",
    "# with lq.context.quantized_scope(True):\n",
    "#     weights = model.layers[3].get_weights()\n",
    "#     print(weights)\n",
    "\n",
    "#     if len(weights) > 0:\n",
    "#         weight_array = weights[0] \n",
    "#         print(\"Weights shape:\", weight_array.shape)\n",
    "#     else:\n",
    "#         print(\"No weights found in this layer.\")\n",
    "\n",
    "# print(weights[0].shape)\n",
    "# rows, cols, _, output_channels = weights[0].shape\n",
    "# print(rows, cols, output_channels)\n",
    "# for col in range(cols):\n",
    "#     for row in range(rows):\n",
    "#         for output_channel in range(output_channels):\n",
    "#             print(row, col, output_channel, weights[0][row][col][0][output_channel])\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        beta, moving_mean, moving_variance = layer.get_weights()\n",
    "        print(f\"Layer: {layer.name}\")\n",
    "        print(f\"  Beta (offset): {beta}\")\n",
    "        print(f\"Beta Length: {len(beta)}\")\n",
    "        print(f\"  Moving Mean: {moving_mean}\")\n",
    "        print(f\" Moving Mean Length: {len(moving_mean)}\")\n",
    "        print(f\"  Moving Variance: {moving_variance}\")\n",
    "        print(f\"  Moving Variance Length: {len(moving_variance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: batch_normalization, Input shape: (None, 12, 12, 32)\n",
      "Layer: batch_normalization_1, Input shape: (None, 5, 5, 32)\n",
      "Layer: batch_normalization_2, Input shape: (None, 128)\n",
      "Layer: batch_normalization_3, Input shape: (None, 10)\n"
     ]
    }
   ],
   "source": [
    "input_shape_callback = InputShapeCallback()\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        input_shape = layer.input_shape\n",
    "        print(f\"Layer: {layer.name}, Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"gen_hdl\"):\n",
    "    os.mkdir(\"gen_hdl\")\n",
    "\n",
    "# Extract weights\n",
    "betas = []\n",
    "moving_means = []\n",
    "moving_variances = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        beta, moving_mean, moving_variance = layer.get_weights()\n",
    "        betas.append(beta)\n",
    "        moving_means.append(moving_mean)\n",
    "        moving_variances.append(moving_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bn(beta, moving_mean, moving_variance, num: int):\n",
    "\n",
    "    # thresholds = np.zeros(len(beta))\n",
    "    compare = \"\"\n",
    "    for output_neuron in range(len(beta)):\n",
    "        # print(len(beta))\n",
    "        threshold = moving_mean[output_neuron] - beta[output_neuron] * np.sqrt(moving_variance[output_neuron])\n",
    "        compare += f\"   assign o_data[{output_neuron}] = i_data[{output_neuron}] > {threshold} ? 1 : 0;\\n\"\n",
    "\n",
    "    output_hdl = templates.BN_TEMPLATE \\\n",
    "        .replace(\"%DIM_DATA%\", str(len(beta))) \\\n",
    "        .replace(\"%LAYER_NUM%\", str(num)) \\\n",
    "        .replace(\"%COMPARE%\", compare)\n",
    "        \n",
    "    with open(f\"gen_hdl/bn_layer_{num}.v\", \"w\") as f:\n",
    "        f.write(output_hdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(betas)):\n",
    "    parse_bn(betas[n], moving_means[n], moving_variances[n], n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
