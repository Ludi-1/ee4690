{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "938/938 [==============================] - 21s 20ms/step - loss: 0.6583 - accuracy: 0.9079\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.4994 - accuracy: 0.9584\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.4739 - accuracy: 0.9646\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.4636 - accuracy: 0.9686\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4583 - accuracy: 0.9703\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.4552 - accuracy: 0.9711\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5086 - accuracy: 0.9685\n",
      "+sequential stats-----------------------------------------------------------------------------+\n",
      "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs |\n",
      "|                              (bit)                        x 1       x 1    (kB)             |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d                     1  (-1, 25, 25, 32)      512         0    0.06      320000 |\n",
      "| max_pooling2d                    -  (-1, 12, 12, 32)        0         0       0           0 |\n",
      "| batch_normalization              -  (-1, 12, 12, 32)        0        64    0.25           0 |\n",
      "| quant_conv2d_1                   1  (-1, 10, 10, 32)     9216         0    1.12      921600 |\n",
      "| max_pooling2d_1                  -    (-1, 5, 5, 32)        0         0       0           0 |\n",
      "| batch_normalization_1            -    (-1, 5, 5, 32)        0        64    0.25           0 |\n",
      "| flatten                          -         (-1, 800)        0         0       0           0 |\n",
      "| quant_dense                      1         (-1, 128)   102400         0   12.50      102400 |\n",
      "| batch_normalization_2            -         (-1, 128)        0       256    1.00           0 |\n",
      "| quant_dense_1                    1          (-1, 10)     1280         0    0.16        1280 |\n",
      "| batch_normalization_3            -          (-1, 10)        0        20    0.08           0 |\n",
      "| activation                       -          (-1, 10)        0         0       0           ? |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "| Total                                                  113408       404   15.42     1345280 |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "+sequential summary----------------------------+\n",
      "| Total params                      114 k      |\n",
      "| Trainable params                  113 k      |\n",
      "| Non-trainable params              404        |\n",
      "| Model size                        15.42 KiB  |\n",
      "| Model size (8-bit FP weights)     14.24 KiB  |\n",
      "| Float-32 Equivalent               444.58 KiB |\n",
      "| Compression Ratio of Memory       0.03       |\n",
      "| Number of MACs                    1.35 M     |\n",
      "| Ratio of MACs that are binarized  1.0000     |\n",
      "+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Define NN topology\n",
    "2. Train NN\n",
    "3. Generate HDL\n",
    "\"\"\"\n",
    "\n",
    "# Libraries\n",
    "import larq as lq\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import templates\n",
    "\n",
    "# Image dataset\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "input_shape = (28, 28, 1) # Input img shape\n",
    "filters_a = 32 # Number of output channels\n",
    "kernel_three = (4, 4) # Kernel dimension\n",
    "\n",
    "filters_b = 32 # Number of output channels\n",
    "kernel_b = (3, 3) # Kernel dimension\n",
    "\n",
    "# Prepare dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# print_image(train_images[0])\n",
    "# Normalize pixel values to be between -1 and 1\n",
    "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(filters_a, kernel_three,\n",
    "                                input_quantizer=\"ste_sign\",\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(lq.layers.QuantConv2D(filters_b, kernel_b,\n",
    "                                input_quantizer=\"ste_sign\",\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(lq.layers.QuantDense(128, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# # model.add(lq.layers.QuantDense(500, use_bias=False, **kwargs))\n",
    "# model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "# model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "output_shapes = [layer.output_shape for layer in model.layers]\n",
    " \n",
    "heights = []\n",
    "widths = []\n",
    "channels = []\n",
    " \n",
    "for shape in output_shapes:\n",
    "    if len(shape) == 4:  \n",
    "        _, height, width, channel = shape\n",
    "        heights.append(height)\n",
    "        widths.append(width)\n",
    "        channels.append(channel)\n",
    "    elif len(shape) == 2:  \n",
    "        _, channel = shape\n",
    "        heights.append(None)\n",
    "        widths.append(None)\n",
    "        channels.append(channel)\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=64, epochs=6)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "lq.models.summary(model)\n",
    "\n",
    "if not os.path.exists(\"gen_hdl\"):\n",
    "    os.mkdir(\"gen_hdl\")\n",
    "  \n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        beta, moving_mean, moving_variance = layer.get_weights()\n",
    "        # print(f\"Layer: {layer.name}\")\n",
    "        # print(f\"  Beta (offset): {beta}\")\n",
    "        # print(f\"Beta Length: {len(beta)}\")\n",
    "        # print(f\"  Moving Mean: {moving_mean}\")\n",
    "        # print(f\" Moving Mean Length: {len(moving_mean)}\")\n",
    "        # print(f\"  Moving Variance: {moving_variance}\")\n",
    "        # print(f\"  Moving Variance Length: {len(moving_variance)}\")\n",
    "\n",
    "\n",
    "### PARSE FC FUNC\n",
    "betas = []\n",
    "moving_means = []\n",
    "moving_variances = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        beta, moving_mean, moving_variance = layer.get_weights()\n",
    "        betas.append(beta)\n",
    "        moving_means.append(moving_mean)\n",
    "        moving_variances.append(moving_variance)\n",
    "      \n",
    "def parse_bn(beta, moving_mean, moving_variance, num: int):\n",
    "\n",
    "    # thresholds = np.zeros(len(beta))\n",
    "    compare = \"\"\n",
    "    for output_neuron in range(len(beta)):\n",
    "        # print(len(beta))\n",
    "        threshold = moving_mean[output_neuron] - beta[output_neuron] * np.sqrt(moving_variance[output_neuron])\n",
    "        compare += f\"   assign o_data[{output_neuron}] = i_data[{output_neuron}] > {threshold} ? 1 : 0;\\n\"\n",
    "\n",
    "    output_hdl = templates.BN_TEMPLATE \\\n",
    "        .replace(\"%DIM_DATA%\", str(len(beta))) \\\n",
    "        .replace(\"%LAYER_NUM%\", str(num)) \\\n",
    "        .replace(\"%COMPARE%\", compare)\n",
    "        \n",
    "    with open(f\"gen_hdl/bn_layer_{num}.v\", \"w\") as f:\n",
    "        f.write(output_hdl)\n",
    "\n",
    "  \n",
    "# for n in range(len(betas)):\n",
    "#     parse_bn(betas[n], moving_means[n], moving_variances[n], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conv(conv_weights, num : int):\n",
    "\n",
    "    kernel_size, kernel_size, input_channels, output_channels = conv_weights.shape\n",
    "    conv_weights[conv_weights == -1] = 0\n",
    "    conv_weight = np.reshape(conv_weights, (kernel_size**2, input_channels, output_channels))\n",
    "    print(conv_weight.shape)\n",
    "    buffer = \"\"\n",
    "    xnor = \"\"\n",
    "    for i in range(input_channels):\n",
    "        buffer += f\"\"\"ibuf_conv #(\n",
    "                        .img_width(INPUT_DIM),\n",
    "                        .kernel_dim(KERNEL_DIM),\n",
    "                    ) ibuf (\n",
    "                        .clk(clk),\n",
    "                        .i_we(i_we),\n",
    "                        .i_data(i_data[{i}]),\n",
    "                        .o_data(window[{i}]),\n",
    "                    );\\n\"\"\"\n",
    "\n",
    "    for i in range(output_channels):\n",
    "        for j in range(input_channels):\n",
    "            for k in range(kernel_size**2):\n",
    "                weight = conv_weight[k, j, i]\n",
    "                if weight == 0:\n",
    "                    xnor += f\"assign temp[{i*output_channels+j*input_channels+k}] = ~window[{j}][{k}];\\n\" \n",
    "                elif weight == 1:\n",
    "                    xnor += f\"assign temp[{i*output_channels+j*input_channels+k}] = window[{j}][{k}];\\n\" \n",
    "                else:\n",
    "                    raise Exception(f\"neuron value not 0 or 1: {weight}\") \n",
    "            \n",
    "    \n",
    "    output_hdl = templates.CONV_TEMPLATE \\\n",
    "        .replace(\"%BUFFER%\", buffer) \\\n",
    "        .replace(\"%LAYER_NUM%\", str(num)) \\\n",
    "        .replace(\"%XNOR%\", xnor)\n",
    "    with open(f\"gen_hdl/conv_layer_{num}.sv\", \"w\") as f:\n",
    "        f.write(output_hdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Extract weights\n",
    "with lq.context.quantized_scope(True):\n",
    "    weights = np.array(model.layers[3].get_weights())\n",
    "\n",
    "parse_conv(weights[0], 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
